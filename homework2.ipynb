{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXEEmENcUNMk"
      },
      "source": [
        "### Exercise 1.1 : Data Preprocessing (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sC86qzrHUNMo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# reading dataset\n",
        "df = pd.read_csv('Dry_Beans_Dataset.csv')\n",
        "# df.head()\n",
        "\n",
        "# encode as integers\n",
        "myData_encoder = LabelEncoder()\n",
        "myData_encoded =  myData_encoder.fit_transform(df.Class) \n",
        "# print (myData_encoded)\n",
        " \n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False) # disable sparse return type\n",
        "\n",
        "# reshape the array\n",
        "myData_encoded = myData_encoded.reshape(len(myData_encoded), 1) \n",
        "onehot_encoded = onehot_encoder.fit_transform(myData_encoded) \n",
        "\n",
        "#turn encoded data into DataFrame\n",
        "encoded_class = pd.DataFrame(onehot_encoded)\n",
        "\n",
        "#get unique headers into class_head variable\n",
        "class_head = np.unique(np.concatenate(df['Class'].str.split(';\\s*').values))\n",
        "\n",
        "#put headers on encoded_class Datatframe\n",
        "encoded_class.columns = class_head\n",
        "\n",
        "#set scaler for normailze data\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#drop 'Class' header from source DataFrame\n",
        "df.drop(['Class'], axis = 1, inplace = True)\n",
        "\n",
        "#transform data into normalized decimal between 0 and 1\n",
        "for x in df.columns:\n",
        "    cur = df[x]\n",
        "    cur = [[i] for i in cur]\n",
        "    scaled = scaler.fit_transform(cur)\n",
        "    df[x] = scaled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-nmJ_N4UNMq"
      },
      "source": [
        "### Exercise 1.2 : Training and Testing the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SXA5uVXUNMr",
        "outputId": "4faabada-ea6c-4947-aca4-1de911094598"
      },
      "outputs": [],
      "source": [
        "# Tensorflow / Keras\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import Input\n",
        "from keras.layers import Dense\n",
        "from keras_hist_graph import plot_history\n",
        "\n",
        "# Sklearn\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#x,y labels\n",
        "y = encoded_class\n",
        "x = df\n",
        "\n",
        "#split training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,random_state=1, test_size=0.1)\n",
        "\n",
        "#regression model\n",
        "clf = MLPClassifier(hidden_layer_sizes=(12,3), activation=\"logistic\", solver = 'sgd', learning_rate_init=0.3, max_iter = 500, random_state=1)\n",
        "\n",
        "#fitting training set to regression model\n",
        "hist = clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confusion matrix = \n",
            " [[140   0   8   0   0   0   0]\n",
            " [  0  45   0   0   0   0   0]\n",
            " [  7   0 142   0   1   0   0]\n",
            " [ 25   0   0 292   0   2  29]\n",
            " [  5   0   2   0 179   0   2]\n",
            " [ 10   0   0   0   0 190   6]\n",
            " [ 28   0   1   2   7   2 237]]\n",
            "MSE of the model =  1.4552129221732746\n",
            "         Precision per Bean type\n",
            "0.651163                BARBUNYA\n",
            "1.000000                  BOMBAY\n",
            "0.928105                    CALI\n",
            "0.993197                DERMASON\n",
            "0.957219                   HOROZ\n",
            "0.979381                   SEKER\n",
            "0.864964                    SIRA\n",
            "         Recall per Bean type\n",
            "0.945946             BARBUNYA\n",
            "1.000000               BOMBAY\n",
            "0.946667                 CALI\n",
            "0.839080             DERMASON\n",
            "0.952128                HOROZ\n",
            "0.922330                SEKER\n",
            "0.855596                 SIRA\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "#function to find mse\n",
        "def mse(actual, pred): \n",
        "    actual, pred = np.array(actual), np.array(pred)\n",
        "    return np.square(np.subtract(actual,pred)).mean() \n",
        "\n",
        "#predict y using x_test\n",
        "y_pred = clf.predict(X_test) \n",
        "\n",
        "#turn results into dataframe and give headers\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred.columns = class_head\n",
        "\n",
        "#format for confusion matrix\n",
        "y_test = np.argmax(y_test.values, axis = 1)\n",
        "y_pred = np.argmax(y_pred.values, axis = 1)\n",
        "\n",
        "#print confusion matrix and mse\n",
        "print(\"confusion matrix = \\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"MSE of the model = \", mse(y_test,y_pred))\n",
        "\n",
        "# format dataframe for precision\n",
        "precision_df = pd.DataFrame(class_head, precision_score(y_test,y_pred, pos_label=1, average = None))\n",
        "precision_df.columns = ['Precision per Bean type']\n",
        "\n",
        "# format dataframe for recall\n",
        "recall_df = pd.DataFrame(class_head, recall_score(y_test,y_pred, pos_label=1, average = None))\n",
        "recall_df.columns = ['Recall per Bean type']\n",
        "\n",
        "#print precision and recall\n",
        "print(precision_df)\n",
        "print(recall_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2 : k-fold Cross Validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "\n",
        "#define cross-validation method to use \n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "#use k-fold CV to evaluate model (random sampling to ensure there is no bias)\n",
        "scores = cross_validate(clf, x, y, cv=cv, scoring=('accuracy','neg_mean_squared_error'), return_train_score=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE for each train set: \n",
            " [0.02326721 0.02298542 0.02509621 0.0248863  0.02218076 0.02697376\n",
            " 0.0357551  0.02635569 0.03297959 0.0238484 ] \n",
            "\n",
            "Average MSE for train set: \n",
            " 0.026432842997595806 \n",
            "\n",
            "Accuracy for each train set: \n",
            " [0.90358397 0.89844898 0.89085714 0.89020408 0.90963265 0.86979592\n",
            " 0.8157551  0.88644898 0.86481633 0.90114286] \n",
            "\n",
            "Average Accuracy for train set: \n",
            " 0.8830686006854371 \n",
            "\n",
            "MSE for each test set: \n",
            " [0.02045312 0.02445681 0.02424688 0.02466674 0.02718589 0.02697596\n",
            " 0.03516322 0.02813058 0.03264406 0.02708093] \n",
            "\n",
            "Average MSE for test set: \n",
            " 0.027100418055986487 \n",
            "\n",
            "Accuracy for each test set: \n",
            " [0.91483113 0.89199118 0.89860397 0.8853784  0.89346069 0.86554004\n",
            " 0.81631154 0.87729611 0.8662748  0.89272594] \n",
            "\n",
            "Average Accuracy for test set: \n",
            " 0.8802413790499125 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print(scores.keys())\n",
        "\n",
        "print('MSE for each train set: \\n', abs(scores['train_neg_mean_squared_error']), \"\\n\")\n",
        "print('Average MSE for train set: \\n', mean(abs(scores['train_neg_mean_squared_error'])), \"\\n\")\n",
        "print('Accuracy for each train set: \\n', scores['train_accuracy'], \"\\n\")\n",
        "print('Average Accuracy for train set: \\n', mean(scores['train_accuracy']), \"\\n\")\n",
        "\n",
        "print('MSE for each test set: \\n', abs(scores['test_neg_mean_squared_error']), \"\\n\")\n",
        "print('Average MSE for test set: \\n', mean(abs(scores['test_neg_mean_squared_error'])), \"\\n\")\n",
        "print('Accuracy for each test set: \\n', scores['test_accuracy'], \"\\n\")\n",
        "print('Average Accuracy for test set: \\n', mean(scores['test_accuracy']), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3 : Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
              "             estimator=MLPClassifier(activation='logistic',\n",
              "                                     hidden_layer_sizes=(12, 3),\n",
              "                                     learning_rate_init=0.3, max_iter=500,\n",
              "                                     random_state=1, solver='sgd'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'hidden_layer_sizes': [(14, 4), (13, 6), (13, 5),\n",
              "                                                (14, 5)],\n",
              "                         'learning_rate_init': [0.055, 0.065, 0.05, 0.04, 0.02,\n",
              "                                                0.009, 0.045],\n",
              "                         'max_iter': array([692, 883, 518, 797, 459, 440, 545])},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform as sp_randFloat\n",
        "from scipy.stats import randint as sp_randInt\n",
        "\n",
        "#generate 7 random ints between 400 and 999\n",
        "mi = sp_randInt(400,999).rvs(7)\n",
        "\n",
        "#list of parameters to test with test values in array\n",
        "hyperparameter_space = {'hidden_layer_sizes':[(14,4),(13,6),(13,5),(14,5)], \n",
        "                        'learning_rate_init':[.055,.065,.05, .04, .02, .009, .045],\n",
        "                        'max_iter': mi}\n",
        "\n",
        "#model using clf as regression, testing param_distributions, rating by accuracy, n_jobs=-1 to use all cpu cores, \n",
        "gridSearch = GridSearchCV(clf, param_grid=hyperparameter_space, scoring = \"accuracy\", n_jobs=-1, cv=cv, return_train_score=False)\n",
        "\n",
        "#fit x and y to randomized model\n",
        "gridSearch.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Results from Random Search: \n",
            "\n",
            "-----------------------------\n",
            "The best estimator across ALL searched params: MLPClassifier(activation='logistic', hidden_layer_sizes=(13, 5),\n",
            "              learning_rate_init=0.065, max_iter=692, random_state=1,\n",
            "              solver='sgd')\n",
            "The best Accuracy across ALL searched params: 0.9141866835843473\n",
            "The best parameters across ALL searched params: {'hidden_layer_sizes': (13, 5), 'learning_rate_init': 0.065, 'max_iter': 692}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\" Results from Random Search: \\n\" )\n",
        "print('-----------------------------')\n",
        "print(\"The best estimator across ALL searched params:\", gridSearch.best_estimator_)\n",
        "print(\"The best Accuracy across ALL searched params:\", gridSearch.best_score_)\n",
        "print(\"The best parameters across ALL searched params:\", gridSearch.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "homework2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7301a6acfd0212fd833029ad4b8827843ad5f4b46505c3f18e44ed888fde5a4d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
